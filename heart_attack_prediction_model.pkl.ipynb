{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyODw9kww9xXguuHNz+sBoPh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Heart Attack Prediction Model**"],"metadata":{"id":"zgn1UnVN87Xe"}},{"cell_type":"markdown","source":["### Project Setup"],"metadata":{"id":"HNPxPXrJ9DGt"}},{"cell_type":"code","source":["# Install required packages\n","!pip install numpy pandas matplotlib seaborn scikit-learn tensorflow keras xgboost imbalanced-learn shap eli5"],"metadata":{"id":"qIEfracL8-tg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import  libraries:"],"metadata":{"id":"aKRsEn769Y4I"}},{"cell_type":"code","source":["# Import basic libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Scikit-learn tools\n","from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n","                             roc_auc_score, confusion_matrix, classification_report,\n","                             roc_curve, precision_recall_curve)\n","\n","# ML algorithms\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.svm import SVC\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# XGBoost\n","import xgboost as xgb\n","\n","# Imbalanced data handling\n","from imblearn.over_sampling import SMOTE\n","from imblearn.pipeline import Pipeline as ImbPipeline\n","\n","# Visualization & interpretation\n","import shap\n","import eli5\n","from eli5.sklearn import PermutationImportance\n","\n","# Warnings\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","\n","# Set Seaborn theme and color palette\n","sns.set_theme(style=\"whitegrid\", palette=\"viridis\")\n","\n","sns.set_palette('viridis')\n","\n","# Set random seed for reproducibility\n","np.random.seed(42)\n","\n","# For Jupyter notebooks (optional, uncomment if using Jupyter)\n","# %matplotlib inline\n"],"metadata":{"id":"gtpgdwDe9XdI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **2. Data Collection and Exploration**"],"metadata":{"id":"u_UcyTPq_qp6"}},{"cell_type":"markdown","source":["### Load the Heart Disease Dataset"],"metadata":{"id":"Yem2g3O8_zMk"}},{"cell_type":"code","source":["# Load the Cleveland Heart Disease dataset\n","url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n","column_names = [\n","    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n","    'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'\n","]\n","data = pd.read_csv(url, header=None, names=column_names, na_values='?')\n","\n","# Display the first few rows\n","print(f\"Dataset shape: {data.shape}\")\n","data.head()"],"metadata":{"id":"U2zyXSPE9XgI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","print(data.shape)"],"metadata":{"id":"w5LboV5X9Xij"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Understanding the Data"],"metadata":{"id":"sqH_qrkWAOe4"}},{"cell_type":"code","source":["data.info()\n","\n","print(\"Missing values per column:\")\n","print(data.isnull().sum())\n"],"metadata":{"id":"iew7OG6W9Xk0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.describe()"],"metadata":{"id":"zDJevOkc9XnR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **EDA ANALYSIS**"],"metadata":{"id":"0i_Jqmx_A2f7"}},{"cell_type":"code","source":["plt.figure(figsize=(15, 10))\n","\n","numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n","for i, feature in enumerate(numerical_features):\n","    plt.subplot(2, 3, i+1)\n","    sns.histplot(data=data, x=feature, hue='target', kde=True, bins=30)\n","    plt.title(f'Distribution of {feature}')\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"2U_oGYgBA2J4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8, 6))\n","\n","target_counts = data['target'].value_counts()\n","\n","\n","labels = [f'{cls}: {count}' for cls, count in zip(target_counts.index, target_counts.values)]\n","\n","colors = ['blue', 'yellow', 'lightgreen', 'orange'][:len(target_counts)]\n","\n","# Plot pie chart\n","plt.pie(target_counts, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\n","plt.title('Target Distribution')\n","plt.show()\n"],"metadata":{"id":"ywSLUD03BhxS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# correaltion of Heatmap"],"metadata":{"id":"XGx_WUquDPuW"}},{"cell_type":"code","source":["plt.figure(figsize=(12, 10))\n","correlation = data.corr()\n","mask = np.triu(correlation)\n","sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', mask=mask, linewidths=0.5)\n","plt.title('Correlation Matrix')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"nP5Mx48zDPc2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(15, 10))\n","for i, feature in enumerate(numerical_features):\n","    plt.subplot(2, 3, i+1)\n","    sns.boxplot(x='target', y=feature, data=data)\n","    plt.title(f'{feature} vs. Heart Disease')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"TzfmrAsGDe2-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n","plt.figure(figsize=(20, 15))\n","for i, feature in enumerate(categorical_features):\n","    plt.subplot(3, 3, i+1)\n","    feature_data = pd.crosstab(data[feature], data['target'])\n","    feature_data.plot(kind='bar', stacked=True, ax=plt.gca())\n","    plt.title(f'{feature} vs. Heart Disease')\n","    plt.xlabel(feature)\n","    plt.ylabel('Count')\n","    plt.legend(['No Disease', 'Disease'])\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"d1LJmHywD-Lj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Feature Interactions"],"metadata":{"id":"RVBWmpYKFAgs"}},{"cell_type":"code","source":["# Create pair plots for interesting feature combinations\n","sns.pairplot(data[['age', 'thalach', 'chol', 'oldpeak', 'target']], hue='target', diag_kind='kde')\n","plt.suptitle('Pair Plot of Key Features', y=1.02)\n","plt.show()\n","\n","# Age and gender analysis\n","plt.figure(figsize=(12, 6))\n","sns.violinplot(x='sex', y='age', hue='target', data=data, split=True, inner='quart')\n","plt.title('Age Distribution by Gender and Heart Disease')\n","plt.xlabel('Sex (0=Female, 1=Male)')\n","plt.ylabel('Age')\n","plt.show()"],"metadata":{"id":"m0Dwd1LMEnEk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **3. Data Preprocessing**"],"metadata":{"id":"C52YOxyBFMcT"}},{"cell_type":"code","source":["print(\"Missing values before handling:\")\n","print(data.isnull().sum())\n"],"metadata":{"id":"B0KLUxrpFKLJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["columns_to_impute = ['ca', 'thal']\n","data[columns_to_impute] = data[columns_to_impute].fillna(data[columns_to_impute].median())\n","print(\"\\nMissing values after handling:\")\n","print(data.isnull().sum())\n"],"metadata":{"id":"lauQXdZ1GRuB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert target variable - if target>0, then 1, otherwise 0\n","data['target'] = data['target'].apply(lambda x: 1 if x > 0 else 0)\n","print(\"Target variable distribution after conversion:\")\n","print(data['target'].value_counts())"],"metadata":{"id":"59i2g9H5GWS2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split features and target\n","X = data.drop('target', axis=1)\n","y = data['target']\n","\n","# Split into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n","print(f\"Testing set shape: {X_test.shape}, {y_test.shape}\")"],"metadata":{"id":"pkbRTpO8GWPq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Scale numerical features\n","numerical_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n","scaler = StandardScaler()\n","\n","X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n","X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n"],"metadata":{"id":"wHUUUdvYGWNP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('heart_scaler.pkl', 'wb') as f:\n","    pickle.dump(scaler, f)\n","\n","print(\"Scaled features:\")\n","X_train[numerical_features].describe()"],"metadata":{"id":"dh9ZsWsOHDYq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.head()"],"metadata":{"id":"-Ym4E2rdHN80"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. Feature Engineering"],"metadata":{"id":"95mExSGOHY1Y"}},{"cell_type":"code","source":["# Create new features\n","def add_features(df):\n","    # Age and cholesterol interaction\n","    df['age_chol_ratio'] = df['age'] / df['chol']\n","\n","    # Heart rate reserve (approximate)\n","    df['max_heart_rate'] = 220 - df['age']\n","    df['heart_rate_reserve'] = df['max_heart_rate'] - df['thalach']\n","\n","    # Blood pressure and cholesterol risk\n","    df['bp_chol_product'] = df['trestbps'] * df['chol'] / 1000\n","\n","    # Exercise-induced ST depression severity\n","    df['exang_oldpeak'] = df['exang'] * df['oldpeak']\n","\n","    return df\n","\n","X_train = add_features(X_train)\n","X_test = add_features(X_test)\n","\n","print(\"New features added:\")\n","print(X_train.columns.tolist())"],"metadata":{"id":"JTSmlWOUHO-3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check class balance\n","print(\"Original class distribution:\")\n","print(y_train.value_counts())\n","\n","# Apply SMOTE to balance the training set\n","smote = SMOTE(random_state=42)\n","X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n","\n","print(\"\\nBalanced class distribution:\")\n","print(pd.Series(y_train_balanced).value_counts())\n","\n","# Visualize class distribution before and after SMOTE\n","plt.figure(figsize=(12, 5))\n","\n","plt.subplot(1, 2, 1)\n","sns.countplot(x=y_train)\n","plt.title('Original Class Distribution')\n","\n","plt.subplot(1, 2, 2)\n","sns.countplot(x=y_train_balanced)\n","plt.title('Balanced Class Distribution after SMOTE')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"ddgLQ43yH3MM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **5. Model Selection and Training**"],"metadata":{"id":"ls_f1pkXH73t"}},{"cell_type":"code","source":["def evaluate_model(model, X_train, y_train, X_test, y_test, model_name=\"Model\"):\n","    \"\"\"Evaluate model performance with multiple metrics\"\"\"\n","    # Train the model\n","    model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    y_pred = model.predict(X_test)\n","    y_prob = model.predict_proba(X_test)[:, 1]\n","\n","    # Calculate metrics\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred)\n","    recall = recall_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred)\n","    auc = roc_auc_score(y_test, y_prob)\n","\n","    # Print results\n","    print(f\"{model_name} Performance:\")\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","    print(f\"Precision: {precision:.4f}\")\n","    print(f\"Recall: {recall:.4f}\")\n","    print(f\"F1 Score: {f1:.4f}\")\n","    print(f\"ROC AUC: {auc:.4f}\")\n","    print(\"\\nClassification Report:\")\n","    print(classification_report(y_test, y_pred))\n","\n","    # Plot confusion matrix\n","    plt.figure(figsize=(8, 6))\n","    cm = confusion_matrix(y_test, y_pred)\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n","    plt.title(f'Confusion Matrix - {model_name}')\n","    plt.xlabel('Predicted')\n","    plt.ylabel('Actual')\n","    plt.show()\n","\n","    # Plot ROC curve\n","    plt.figure(figsize=(8, 6))\n","    fpr, tpr, _ = roc_curve(y_test, y_prob)\n","    plt.plot(fpr, tpr, label=f'AUC = {auc:.4f}')\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(f'ROC Curve - {model_name}')\n","    plt.legend(loc='lower right')\n","    plt.show()\n","\n","    return {\n","        'model': model,\n","        'accuracy': accuracy,\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1,\n","        'auc': auc,\n","        'y_pred': y_pred,\n","        'y_prob': y_prob\n","    }"],"metadata":{"id":"649hj0--H9Jb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define models to try\n","models = {\n","    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n","    'Random Forest': RandomForestClassifier(random_state=42),\n","    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n","    'XGBoost': xgb.XGBClassifier(random_state=42),\n","    'SVM': SVC(probability=True, random_state=42),\n","    'Neural Network': MLPClassifier(max_iter=1000, random_state=42)\n","}\n","\n","# Train and evaluate each model\n","results = {}\n","for name, model in models.items():\n","    print(f\"Training {name}...\")\n","    result = evaluate_model(model, X_train_balanced, y_train_balanced, X_test, y_test, name)\n","    results[name] = result\n","    print(\"-\" * 50)"],"metadata":{"id":"5FBd1QW8IG8A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compare model performance\n","performance_df = pd.DataFrame({\n","    'Model': list(results.keys()),\n","    'Accuracy': [results[m]['accuracy'] for m in results],\n","    'Precision': [results[m]['precision'] for m in results],\n","    'Recall': [results[m]['recall'] for m in results],\n","    'F1 Score': [results[m]['f1'] for m in results],\n","    'AUC': [results[m]['auc'] for m in results]\n","})\n","\n","# Sort by accuracy\n","performance_df = performance_df.sort_values('Accuracy', ascending=False).reset_index(drop=True)\n","print(\"Model Performance Comparison:\")\n","print(performance_df)\n","\n","# Visualize model comparison\n","plt.figure(figsize=(15, 10))\n","metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC']\n","for i, metric in enumerate(metrics):\n","    plt.subplot(2, 3, i+1)\n","    sns.barplot(x='Model', y=metric, data=performance_df)\n","    plt.title(f'Model Comparison - {metric}')\n","    plt.xticks(rotation=45, ha='right')\n","    plt.ylim(0.5, 1.0)  # Set reasonable y-limits for better comparison\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"gjZSvycsILjA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **6. Model Evaluation**"],"metadata":{"id":"3xDUqS_dIXe3"}},{"cell_type":"code","source":["# Select the best performing model\n","best_model_name = performance_df.iloc[0]['Model']\n","best_model = results[best_model_name]['model']\n","print(f\"Best performing model: {best_model_name} with accuracy: {performance_df.iloc[0]['Accuracy']:.4f}\")"],"metadata":{"id":"Az_N0HOxIWuX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Perform cross-validation on the best model\n","cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","cv_scores = cross_val_score(best_model, X_train_balanced, y_train_balanced, cv=cv, scoring='accuracy')\n","\n","print(f\"Cross-validation scores: {cv_scores}\")\n","print(f\"Mean CV score: {cv_scores.mean():.4f}\")\n","print(f\"Standard deviation: {cv_scores.std():.4f}\")"],"metadata":{"id":"efRQQin9Ij_H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Feature importance analysis\n","if best_model_name in ['Random Forest', 'Gradient Boosting', 'XGBoost']:\n","    # Direct feature importance from tree-based models\n","    feature_importance = pd.DataFrame({\n","        'Feature': X_train.columns,\n","        'Importance': best_model.feature_importances_\n","    }).sort_values('Importance', ascending=False)\n","\n","    plt.figure(figsize=(12, 8))\n","    sns.barplot(x='Importance', y='Feature', data=feature_importance.head(15))\n","    plt.title(f'Feature Importance - {best_model_name}')\n","    plt.show()\n","\n","else:\n","    # Permutation importance for non-tree-based models\n","    perm = PermutationImportance(best_model, random_state=42).fit(X_test, y_test)\n","    perm_importance = eli5.explain_weights_df(perm, feature_names=X_test.columns.tolist())\n","\n","    plt.figure(figsize=(12, 8))\n","    sns.barplot(x='weight', y='feature', data=perm_importance.head(15))\n","    plt.title(f'Permutation Feature Importance - {best_model_name}')\n","    plt.show()"],"metadata":{"id":"-WUReNN0IoNM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if best_model_name in ['Random Forest', 'Gradient Boosting', 'XGBoost']:\n","    explainer = shap.TreeExplainer(best_model)\n","    shap_values = explainer.shap_values(X_test)"],"metadata":{"id":"hsnxY0fPIr4Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Summary plot - Feature Importance (bar)\n","plt.figure(figsize=(12, 10))\n","shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n","plt.title(f'SHAP Feature Importance - {best_model_name}')\n","plt.show()\n","\n","# Detailed SHAP values summary plot (beeswarm)\n","plt.figure(figsize=(12, 10))\n","shap.summary_plot(shap_values, X_test)\n","plt.title(f'SHAP Summary Plot - {best_model_name}')\n","plt.show()\n"],"metadata":{"id":"WYfdY1X-JYKH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **7. Model Optimization**"],"metadata":{"id":"8ROuMcnpJqgb"}},{"cell_type":"code","source":["# Hyperparameter tuning for the best model\n","if best_model_name == 'Logistic Regression':\n","    param_grid = {\n","        'C': [0.001, 0.01, 0.1, 1, 10, 100],\n","        'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n","        'solver': ['liblinear', 'lbfgs', 'saga']\n","    }\n","\n","elif best_model_name == 'Random Forest':\n","    param_grid = {\n","        'n_estimators': [100, 200, 300],\n","        'max_depth': [None, 10, 20, 30],\n","        'min_samples_split': [2, 5, 10],\n","        'min_samples_leaf': [1, 2, 4]\n","    }\n","\n","elif best_model_name == 'Gradient Boosting':\n","    param_grid = {\n","        'n_estimators': [100, 200, 300],\n","        'learning_rate': [0.01, 0.1, 0.2],\n","        'max_depth': [3, 4, 5],\n","        'subsample': [0.8, 0.9, 1.0]\n","    }\n","\n","elif best_model_name == 'XGBoost':\n","    param_grid = {\n","        'n_estimators': [100, 200, 300],\n","        'learning_rate': [0.01, 0.1, 0.2],\n","        'max_depth': [3, 4, 5],\n","        'colsample_bytree': [0.7, 0.8, 0.9]\n","    }\n","\n","elif best_model_name == 'SVM':\n","    param_grid = {\n","        'C': [0.1, 1, 10, 100],\n","        'gamma': ['scale', 'auto', 0.1, 0.01],\n","        'kernel': ['rbf', 'poly', 'sigmoid']\n","    }\n","\n","else:  # Neural Network\n","    param_grid = {\n","        'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n","        'activation': ['relu', 'tanh'],\n","        'alpha': [0.0001, 0.001, 0.01],\n","        'learning_rate': ['constant', 'adaptive']\n","    }\n","\n","# Create grid search with cross-validation\n","grid_search = GridSearchCV(\n","    estimator=best_model,\n","    param_grid=param_grid,\n","    cv=5,\n","    scoring='accuracy',\n","    n_jobs=-1,\n","    verbose=2\n",")\n","\n","# Fit grid search\n","grid_search.fit(X_train_balanced, y_train_balanced)\n","\n","# Best parameters and score\n","print(f\"Best parameters: {grid_search.best_params_}\")\n","print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n","\n","# Get the optimized model\n","optimized_model = grid_search.best_estimator_\n","\n","# Evaluate optimized model\n","optimized_results = evaluate_model(\n","    optimized_model,\n","    X_train_balanced,\n","    y_train_balanced,\n","    X_test,\n","    y_test,\n","    f\"Optimized {best_model_name}\"\n",")"],"metadata":{"id":"G_eS_DXVJoDt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a final pipeline that includes preprocessing and the optimized model\n","preprocessor = StandardScaler()\n","\n","# For imbalanced data handling\n","final_pipeline = ImbPipeline([\n","    ('preprocessor', preprocessor),\n","    ('smote', SMOTE(random_state=42)),\n","    ('classifier', optimized_model)\n","])\n","\n","# Fit the final pipeline\n","final_pipeline.fit(X_train[numerical_features], y_train)\n","\n","# Evaluate the pipeline\n","y_pred = final_pipeline.predict(X_test[numerical_features])\n","final_accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Final pipeline accuracy: {final_accuracy:.4f}\")\n","print(classification_report(y_test, y_pred))\n","\n","# Save the final model\n","with open('heart_attack_prediction_model.pkl', 'wb') as f:\n","    pickle.dump(final_pipeline, f)\n","\n","print(\"Final model saved as 'heart_attack_prediction_model.pkl'\")"],"metadata":{"id":"J2eHEELzKwkk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a final pipeline that includes preprocessing and the optimized model\n","preprocessor = StandardScaler()\n","\n","# For imbalanced data handling\n","final_pipeline = ImbPipeline([\n","    ('preprocessor', preprocessor),\n","    ('smote', SMOTE(random_state=42)),\n","    ('classifier', optimized_model)\n","])\n","\n","# Fit the final pipeline\n","final_pipeline.fit(X_train[numerical_features], y_train)\n","\n","# Evaluate the pipeline\n","y_pred = final_pipeline.predict(X_test[numerical_features])\n","final_accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Final pipeline accuracy: {final_accuracy:.4f}\")\n","print(classification_report(y_test, y_pred))\n","\n","# Save the final model\n","with open('heart_attack_prediction_model.pkl', 'wb') as f:\n","    pickle.dump(final_pipeline, f)\n","\n","print(\"Final model saved as 'heart_attack_prediction_model.pkl'\")"],"metadata":{"id":"Sspn5GJALOlq"},"execution_count":null,"outputs":[]}]}